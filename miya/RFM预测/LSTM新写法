# -*- coding: utf-8 -*-
'''
@author: 金容明
@file: tf_lstm_rfm.py
@time: 2019/05/23 11:27
@help: RFM预测模型训练阶段
'''
###引入第三方模块###
import os
import re 
import sys
import time
import datetime
import argparse
import numpy as np
import pandas as pd
import multiprocessing
import tensorflow as tf
import matplotlib.pyplot as plt

from random import shuffle
from tensorflow.contrib import rnn
from tensorflow.python.ops import init_ops


###定义设置LSTM常量###

# 获取buckets的动态参数
FLAGS=None



def Config():
    parser = argparse.ArgumentParser()
    parser.add_argument('--buckets', type = str, default = '', help = 'bueckts桶')
    parser.add_argument('--checkpointDir', type = str, default = '',help = '模型保存路径的默认路径')
    parser.add_argument('--num_classes', type = int, default = 2,help = '预测类别总数')
    parser.add_argument('--max_steps', type = int, default = 10000, help = '训练集最大迭代次数')
    parser.add_argument('--learning_rate', type = float, default = 0.01, help = '学习率' )
    parser.add_argument('--learning_rate_dec',type = float, default = 0.6, help = '学习下降率,指数级别下降。' )
    parser.add_argument('--keep_prob', type = float, default = 0.6, help = 'DropOut训练时最大保留率')
    parser.add_argument('--keep_prob_end', type = float, default = 0.5, help = 'DropOut模型保存时最大保留率')
    parser.add_argument('--time_train_step', type = int, default = 90, help = '训练集的最大天数')
    parser.add_argument('--time_label_step', type = int, default = 1, help = '预测最大天数,我们这次是第30天，所以是1')
    parser.add_argument('--feature_col', type = int, default = 3, help = 'feature维度')
    parser.add_argument('--feature_num', type = int, default = 2, help = 'feature数量')
    parser.add_argument('--model_id_num', type = int, default = 4, help = '模型ID数量')
    parser.add_argument('--feature_col_label', type = int, default = 1, help = 'label的feature维度,默认为1')
    parser.add_argument('--layer_num', type = int, default = 2, help = '网络层数')
    parser.add_argument('--cell_num', type = int, default = 64, help = '神经元个数')
    parser.add_argument('--output_num', type = int, default = 1, help = 'label维度')
    parser.add_argument('--train_feature_start', type = int, default = 3, help = '训练集原始特征维度数')
    parser.add_argument('--l2_normal', type = float, default = 0.0001, help = 'L2正则项')
    parser.add_argument('--max_num', type = float, default = 100, help = '最大迭代次数')
    parser.add_argument('--batch_size',type = int, default = 512, help = '每次迭代数量')
    parser.add_argument('--loss_min',type = float, default = 0.0001, help = '训练集和验证集的最小损失值')
    parser.add_argument('--normal_epsilon',type = float, default = 0.01, help = '标准化中防止除以0的情况所留的小数')
    parser.add_argument('--thread_num', type = int, default = 5, help = '读取数据的线程数量')
    parser.add_argument('--is_training', type = bool, default = True, help = '读取数据是否为训练集，默认为True,False为验证集')
    parser.add_argument('--train_path', type = str, default = 'oss://bucketjrm2.oss-cn-shanghai-internal.aliyuncs.com/data_temp/train*',help = '训练集输入路径')  # 后续需要去掉只剩下train*
    parser.add_argument('--decay_num', type = int, default = 1000, help = '每多少次学习率更新')
    parser.add_argument('--test_path',type = str,default = 'test*',help = '测试集输入路径')
    parser.add_argument('--model_out_path', type = str, default = 'oss://bucketjrm2.oss-cn-shanghai-internal.aliyuncs.com/tensorflow_model/',help = '模型输出路径')
    parser.add_argument('--model_in_path', type = str, default = 'oss://bucketjrm2.oss-cn-shanghai-internal.aliyuncs.com/tensorflow_model/',help = '模型输入路径')
    parser.add_argument('--total_num', type = int, default = 50000, help = '总数据输入数量')
    parser.add_argument('--train_num', type = int, default = 40000, help = '一次获取的训练集输入数量')
    parser.add_argument('--valid_num', type = int, default = 5000, help = '验证集输入数量')
    parser.add_argument('--test_num', type = int, default = 3600000, help = '模型输出数量')
    parser.add_argument('--min_num', type = int, default = 0, help = '最小数值')
    parser.add_argument('--min_after_dequeue', type = int, default = 100, help = '最小出队数,至少达到多少数时，队列才出队。')
    parser.add_argument('--is_single', type = bool, default = True, help = '是否开启单卡多节点/单节点')
    parser.add_argument('--is_distribute', type = bool, default = True, help = '是否开启分布式')
    parser.add_argument('--python_thread', type = int, default = 2, help = 'python的进程数,后续优化需要用到')
    parser.add_argument('--device', type = str, default = 'GPU', help = 'python为GPU还是CPU')
    parser.add_argument('--worker_num', type = int, default = 2, help = '分布式的节点数')
    parser.add_argument('--gpu_num', type = int, default = 2, help = 'GPU个数,在pai里单机最多为2')
    parser.add_argument('--ps_hosts', type = str, default = '', help = 'PS服务器的HOST,默认空,如果是python脚本执行输入ps_host,如果用pai不用管')
    parser.add_argument('--worker_hosts', type = str, default = '', help = 'worker的HOST,默认空,如果是python脚本执行输入ps_host,如果用pai不用管')
    parser.add_argument('--job_name', type = str, default = '', help = 'job名称')
    parser.add_argument('--task_index', type = int, default = 0, help = '每个job第几个task')
    parser.add_argument('--issync', type = int, default = 1, help = '是否采用分布式的同步模式，1表示同步模式，0表示异步模式')

    parser.add_argument('--data_result',type = str,
                        default = 'oss://bucketjrm2.oss-cn-shanghai-internal.aliyuncs.com/data_result/',
                        help = '模型结果输出路径')



    FLAGS, _ = parser.parse_known_args()
    return FLAGS
    
  
## 单机多卡的LSTM
class LstmModelMultiClassfi(object):
    def __init__(self,FLAGS):
        # with tf.device('/cpu:0'):
        print('分布式LSTM模型初始化开始...')
        self.batch_size = FLAGS.batch_size 
        self.keep_prob = FLAGS.keep_prob
        self.gpu_list = [i for i in range(FLAGS.gpu_num)]
        self.gpu_num = FLAGS.gpu_num
        self.time_train_step = FLAGS.time_train_step
        self.feature_col = FLAGS.feature_col
        self.output_num = FLAGS.output_num
        self.num_classes = FLAGS.num_classes
        self.layer_num = FLAGS.layer_num
        self.cell_num = FLAGS.cell_num
        self.l2_normal = FLAGS.l2_normal
        self.normal_epsilon = FLAGS.normal_epsilon
        self.decay_num = FLAGS.decay_num
        self.learning_rate_dec = FLAGS.learning_rate_dec
        self.checkpointDir = FLAGS.checkpointDir
        self.model_out_path = FLAGS.model_out_path
        self.total_num = FLAGS.total_num 
        self.max_num = FLAGS.max_num
        self.loss_min = FLAGS.loss_min
        # 学习率我们用此方法设置为动态
        self.learning_rate = FLAGS.learning_rate
        self.buckets = FLAGS.buckets 
        self.checkpointDir = FLAGS.checkpointDir
        self.thread_num = FLAGS.thread_num
        self.min_after_dequeue = FLAGS.min_after_dequeue
        self.train_feature_start = FLAGS.train_feature_start
        self.feature_col_label = FLAGS.feature_col_label
        self.time_label_step = FLAGS.time_label_step
        self.train_path = FLAGS.train_path
        self.is_training = FLAGS.is_training
        
        
        print('分布式LSTM模型初始化结束...')
            
    
    # 正则化
#     def weight_variable(self, shape, l2):
#             if l2 is not None or l2 != '':
#                 with tf.variable_scope(tf.get_variable_scope(), reuse= tf.get_variable_scope().reuse) :   
#                     regularizer = tf.contrib.layers.l2_regularizer(l2)
#                     weight_decay = tf.get_variable('weight_loss',shape,dtype = tf.float32,initializer = tf.contrib.layers.xavier_initializer(),trainable=True)
#                     tf.add_to_collection('losses', regularizer(weight_decay))
#                     return weight_decay
#             else:
#                 return
            
    # 梯度 
    def average_gradients(self,tower_grads):  
        average_grads = []
        for grad_and_vars in zip(*tower_grads):
            grads = [g for g, _ in grad_and_vars]
            grad = tf.stack(grads, 0)
            grad = tf.reduce_mean(grad, 0)
            grad_and_var = (grad, grad_and_vars[0][1])
            average_grads.append(grad_and_var)
        return average_grads
#         average_grads = []
#         for grad_and_vars in zip(*tower_grads):
#             grads = [tf.expand_dims(g, 0) for g, _ in grad_and_vars]
#             grads = tf.concat(grads, 0)
#             grad = tf.reduce_mean(grads, 0)
#             grad_and_var = (grad, grad_and_vars[0][1])
#             average_grads.append(grad_and_var)
#         return average_grads

    
    
    
    ## 加载数据
    def load_data(self):
        # 读取OSS数
        train_file_path = tf.gfile.Glob(os.path.join(self.buckets,self.train_path))
    
        # 创建tf的reader对象
        reader = tf.TextLineReader()
        # 将OSS数据转成序列格式
        file_name_queue_train = tf.train.string_input_producer(train_file_path)
        # 懒加载序列里的value值。
        key_train,value_train = reader.read(file_name_queue_train)
    
         # 初始化特征列,这行是double类型
        record_defaults_train = [["1.0"],["1.0"],["1.0"],["1.0"],["1.0"],["1.0"],["1.0"]] 
    
        col1, col2, col3, col4, col5, col6, col7 = tf.decode_csv(value_train, record_defaults=record_defaults_train)
    
        # 一次读取大量数据,毕竟是测试集，我们不需要batch读取
        # 注意，该方法返回的是个list，后续如果用矩阵计算，需要转成numpy np.array(list)
        # 我们如果想确定随机打乱数据，可以直接用: 
        feature_train = tf.train.shuffle_batch([col5, col6, col7],batch_size=self.total_num, num_threads=self.thread_num, \
                                               capacity=self.total_num, min_after_dequeue = self.min_after_dequeue)  
        
        init = tf.global_variables_initializer()
        with tf.Session() as sess:  
            sess.run(init)
            
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess = sess,coord = coord)   
            
            data = sess.run([feature_train])
            data = np.array(data)
            # 生成的是三维度，需要转成二维,注意这个二维是跟原维度相同即可。
            data = data.reshape(self.train_feature_start,self.total_num).T     
                        
            # 结束读取数据进程
            coord.request_stop()
            coord.join(threads)
            
        return data


    ## 处理训练集数据
    
    def get_train_data(self,data_train,batch_size,batch_size_first,batch_size_end,train_path,time_train_step,feature_col, \
                       time_label_step,feature_col_label,is_training = True):
        data_temp = data_train
               
        data_temp = data_train[batch_size_first:batch_size_end,:]
        X_train = np.zeros(shape = (1))
        y_train = np.zeros(shape = (1))
    
        X_train = np.delete(X_train,0,axis = 0)
        y_train = np.delete(y_train,0,axis = 0)
        
        # 训练集
        for i in data_temp:
            
            list1 = list(i[0].replace('[','').replace(']','').replace('"','').split(','))
            aa_num = len(list1)
            aa = [ float(list1[t1]) for t1 in range(aa_num) if t1 % (feature_col + 1) != 1 ]
            
            list1 = list(i[1].replace('[','').replace(']','').replace('"','').split(','))
            aa_num = len(list1)
            bb = [ float(list1[t2]) for t2 in range(aa_num) if t2 % (feature_col + 1) != 1 ]
          
            aa = aa + bb
            cc = [float(i) for i in i[2].split(',')]
                 
            X_train = np.append(X_train,aa).reshape(-1,time_train_step * feature_col)
            y_train = np.append(y_train,cc).reshape(-1,time_label_step * feature_col_label)
        
        return X_train,y_train

            
            
    # 创建网络对象 
    def build_model(self,batch_size,keep_prob,x,y,scope,num_classes,layer_num,time_train_step,feature_col,cell_num,l2_normal,normal_epsilon):
        # tf.reset_default_graph()   
        with tf.variable_scope(tf.get_variable_scope(), reuse= tf.AUTO_REUSE) :   
            input_x = [x[i] for i in range(batch_size)]
            input_y = [tf.one_hot(y[j],depth = num_classes) for j in range(batch_size)] 
        
            W = {
                 'in' : tf.get_variable('w_in',shape = [feature_col,cell_num],
                                         dtype = tf.float32,
                                         initializer = tf.contrib.layers.xavier_initializer(),trainable=True),
                 'out' : tf.get_variable('w_out',shape = [cell_num,num_classes],
                                         dtype = tf.float32,
                                         initializer = tf.contrib.layers.xavier_initializer(),trainable=True)
                }
            bias = {
                      'in' : tf.get_variable('b_in',shape = [cell_num], initializer=init_ops.constant_initializer(0.1) ,trainable=True),
                      'out' :tf.get_variable('b_out',shape = [num_classes], initializer=init_ops.constant_initializer(0.1) ,trainable=True)
                    }
            
            gamma = tf.get_variable('gamma_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(1),trainable=True)
            beta = tf.get_variable('beta_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(0),trainable=True)
            lstm_mean = tf.get_variable('lstm_mean_in',shape = [time_train_step * feature_col], initializer=init_ops.constant_initializer(0),trainable=True)
            lstm_variance = tf.get_variable('lstm_variance_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(1),trainable=True)
            
            input_x_normal = tf.nn.batch_normalization(input_x, lstm_mean, lstm_variance, beta, gamma, normal_epsilon)
            
            # input_x_normal = input_x
            # 通过reshape将输入的input_x转化成2维，-1表示函数自己判断该是多少行，列必须是feature_col
            input_x_r = tf.reshape(input_x_normal,[-1,feature_col])                
            
            # relu和dropout操作
            input_x_in_r = tf.nn.relu(tf.matmul(input_x_r,W['in']) + bias['in'])
            input_relu = tf.nn.dropout(input_x_in_r, keep_prob)
            
            # 即LSTM接受：batch_size个，time_train_step行cell_num(神经元个数)列的矩阵
            input_rnn = tf.reshape(input_relu, [-1, time_train_step, cell_num])
            
            # 定义一个带着“开关”的LSTM单层
            def lstm_cell(cell_num,keep_prob):
                cell = rnn.LSTMCell(cell_num, activation = tf.nn.softsign, reuse = tf.get_variable_scope().reuse)
                return rnn.DropoutWrapper(cell, output_keep_prob = keep_prob)
            
            # 拼接网络层 
            lstm_layers = tf.contrib.rnn.MultiRNNCell([lstm_cell(cell_num,keep_prob) for _ in range(layer_num)], state_is_tuple = True)
            # 初始化LSTM网络,以下是固定格式
            init_state = lstm_layers.zero_state(batch_size, dtype = tf.float32)
            # 动态组合
            outputs, state = tf.nn.dynamic_rnn(lstm_layers, inputs = input_rnn, initial_state = init_state, time_major = False)
            h_state = state[-1][1]
            # 我们预测的结果的概率
            logits = tf.matmul(h_state,W['out']) + bias['out']
            # 我们预测的结果
            pre_d = tf.argmax(logits,1)
            # 我们的input_y 是 list类型,与 pre_d 必须要转成tensor才可以。 
            target = tf.argmax(tf.reshape(input_y,[-1,num_classes]),1)
            corr = tf.cast(tf.equal(pre_d,target),tf.float32)
             # 统计正确总数
            correct_num = tf.reduce_sum(corr)
            # 统计acuuary值
            accuracy = tf.reduce_mean(corr)
            
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = input_y,logits = logits)) # 原始LOSS
            regularization_loss = l2_normal * tf.reduce_sum([tf.nn.l2_loss(W['in'])])  # 正则LOSS
            loss = cross_entropy + regularization_loss 
            
            return loss,logits,pre_d,target,correct_num,accuracy
        
    def feed_all_gpu(self,inp_dict, tower_data):
        for i in range(len(self.models)):
            x,y,loss,correct_num,accuracy,grads = self.models[i]
            train_x, train_y = tower_data[i]
            inp_dict[x] = train_x
            inp_dict[y] = train_y
        return inp_dict
    
    # 训练模型
    def train_lstm(self):
        self._graph = tf.Graph()  # 构建在一个图中
        
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True 
        self.session_tf = tf.Session(graph = self._graph,config = config)
        
        # 我们要先构建图，再 session,下面就是图的操作,后续所有操作都用session.
        
        
        with self._graph.as_default():
            print('分布式LSTM模型开始构建...')
            
            # 学习率我们用此方法设置为动态
#             self.learning_rate = FLAGS.learning_rate
            
            global_step = tf.get_variable('global_step', [],initializer=tf.constant_initializer(0), trainable=False)
            self.learning_rate = tf.train.exponential_decay(self.learning_rate,global_step,self.decay_num, self.learning_rate_dec,staircase=True) 
            self.models = []   
            optimizer = tf.contrib.opt.LazyAdamOptimizer(self.learning_rate)
            
            with tf.variable_scope(tf.get_variable_scope(), reuse= tf.AUTO_REUSE):
                for gpu_id in self.gpu_list:
                     with tf.device('/gpu:%d' % gpu_id):        # 初始化第一个设备
                        print ('gpu:%d...'% gpu_id)
                        with tf.name_scope('tower_%d' % gpu_id) as scope:  # 初始化命名空间
                        #with tf.variable_scope('gpu_v', reuse=gpu_id > self.gpu_list[0]):
                            # 我们的x,y是在循环里,所以放到元组中再取出来。
                            x = tf.placeholder(tf.float32,[self.batch_size,self.time_train_step * self.feature_col])
                            y = tf.placeholder(tf.int32,[self.batch_size,self.output_num])
                            loss,logits,pre_d,target,correct_num,accuracy = \
                            self.build_model(self.batch_size,self.keep_prob,x,y,\
                            scope,self.num_classes,self.layer_num,self.time_train_step,self.feature_col,self.cell_num,self.l2_normal,self.normal_epsilon)
                            # 开启共享
                            tf.get_variable_scope().reuse_variables()
                            # 开始计算梯度
                            grads = optimizer.compute_gradients(loss)
                            # self.models.append((loss,correct_num,accuracy,grads))
                            self.models.append((x,y,loss,correct_num,accuracy,grads))
            # 取出我们的x,y,梯度grads,方便后续run.
            x,y,loss,correct_num,accuracy,grads = zip(*(self.models))
            
            self.loss = tf.reduce_mean(loss)
            self.correct_num = tf.reduce_mean(correct_num)
            self.accuracy = tf.reduce_mean(accuracy)
            self.train_op = optimizer.apply_gradients(self.average_gradients(grads),global_step = global_step)                                                          
            # init = tf.global_variables_initializer()   
            ckpt_path = os.path.join(self.checkpointDir, self.model_out_path)
            saver = tf.train.Saver()
            
           
        #别忘了开启session时调用我们上面的图
        # with tf.Session(config = config,graph = g1) as sess:   
            try:
                module_file = os.path.join(self.checkpointDir, self.model_out_path)
                print('模型参数路径: ',module_file)
                saver.restore(self.session_tf, module_file)
                print ("成功加载模型参数")        
            except:
                #如果是第一次运行，通过init告知tf加载并初始化变量
                print ("没有加载成功，进行初始化操作,开始训练模型...")
                self.session_tf.run(tf.global_variables_initializer())
            
            # 训练集读取
            NUM = self.total_num // self.batch_size
            for z in range(self.max_num):
                # 加载数据
                data = self.load_data()
                tower_data = []
                try:
                    for i in range(NUM):              
                        # 读取训练数据集
                        # 有多少个GPU,就读取多少次。
                        # tower_data = [] 
                        train_x, train_y = self.get_train_data(data_train = data,batch_size = self.batch_size,batch_size_first = 0 + i * self.batch_size , batch_size_end = self.batch_size + i * self.batch_size,train_path = self.train_path,time_train_step = self.time_train_step,feature_col = self.feature_col, time_label_step = self.time_label_step,feature_col_label = self.feature_col_label, is_training = self.is_training)                       
                        
                        tower_data.append((train_x, train_y))
                        
                        if i % self.gpu_num == 1:
                            feed_dict = {}
  
                            feed_dict = self.feed_all_gpu(feed_dict,tower_data)
                            _, train_loss, correct_num_d,accuracy_d = self.session_tf.run([self.train_op,self.loss,self.correct_num,self.accuracy], feed_dict = feed_dict)
                            tower_data = []  

                            # if i % 20 == 0:
                            print("epoch: {0}, step: {1},train_loss: {2},correct_num: {3},accuracy: {4}".format(z + 1,i+1,train_loss,correct_num_d,accuracy_d))
                            # saver.save(self.session_tf,ckpt_path)
                            if train_loss < self.loss_min:
                                print ("训练集均已训练完毕,开始保存模型...")
                                save_path = saver.save(self.session_tf,ckpt_path)
                                print('模型路径为: ',save_path)
                                return 
                            
                        
                        # for j in range(1,self.gpu_num + 1):
                            
                        
#                         feed_dict = {}
#                         feed_dict = self.feed_all_gpu(feed_dict,tower_data)
            
#                         _, train_loss, correct_num_d,accuracy_d = self.session_tf.run([self.train_op,self.loss,self.correct_num,self.accuracy], feed_dict = feed_dict)
                                   
#                         if i % 20 == 0:
#                             print("epoch: {0}, step: {1},train_loss: {2},correct_num: {3},accuracy: {4".format(z + 1,i+1, \
#                                                                                     train_loss,correct_num_d,accuracy_d))
#                             saver.save(self.session_tf,ckpt_path)
#                         if train_loss < self.loss_min:
#                             print ("训练集均已训练完毕,开始保存模型...")
#                             save_path = saver.save(self.session_tf,ckpt_path)
#                             print('模型路径为: ',save_path)
#                             return 
                        
                
                        # 每经历一次遍历,模型保存一次.
                    saver.save(self.session_tf,ckpt_path)
    
                    # 防止迭代超出范围,我们设定StopIteration异常,如果执行下面步骤说明迭代已经到了上限,此时我们执行最后一次，然后开始保存模型。
                except StopIteration:
                    print ("训练集均已训练完毕,开始保存模型...")
                    save_path = saver.save(self.session_tf,ckpt_path)
                    print('模型路径为: ',save_path)
                    break  
        
        print('模型训练结束...')
        
        return self
  

  ## 分布式的LSTM
class LstmModelMultiClassfiDis(object):
    def __init__(self,FLAGS):
        # with tf.device('/cpu:0'):
        print('分布式LSTM模型初始化开始...')
        self.ps_hosts = FLAGS.ps_hosts.split(",")
        self.worker_hosts = FLAGS.worker_hosts.split(",")
        # 开启PS服务器和worker节点IP的服务端
        '''
        需要把你要跑这个任务的所有的ps和worker 的节点的ip和端口的信息都包含进去，
        所有的节点都要执行这段代码， 就大家互相知道了， 这个集群里面都有哪些成员，不同的成员的类型是什么， 是ps节点还是worker节点。
        '''
        self.cluster = tf.train.ClusterSpec({"ps": self.ps_hosts, "worker": self.worker_hosts})
        # 启动我们的服务端
        '''
        tf.train.Server这个的定义开始，就每个节点不一样了。 根据执行的命令的参数不同，决定了这个任务是哪个任务。
        如果任务名字是ps的话， 程序就join到这里，作为参数更新的服务， 等待其他worker节点给他提交参数更新的数据。
        如果是worker任务，就执行后面的计算任务。
        '''
        self.server = tf.train.Server(self.cluster,job_name=FLAGS.job_name,task_index=FLAGS.task_index)
        self.issync = FLAGS.issync
        self.job_name = FLAGS.job_name
        self.task_index = FLAGS.task_index
        self.worker_num = FLAGS.worker_num
        
        self.batch_size = FLAGS.batch_size 
        self.keep_prob = FLAGS.keep_prob
        self.gpu_list = [i for i in range(FLAGS.gpu_num)]
        self.gpu_num = FLAGS.gpu_num
        self.time_train_step = FLAGS.time_train_step
        self.feature_col = FLAGS.feature_col
        self.output_num = FLAGS.output_num
        self.num_classes = FLAGS.num_classes
        self.layer_num = FLAGS.layer_num
        self.cell_num = FLAGS.cell_num
        self.l2_normal = FLAGS.l2_normal
        self.normal_epsilon = FLAGS.normal_epsilon
        self.decay_num = FLAGS.decay_num
        self.learning_rate_dec = FLAGS.learning_rate_dec
        self.checkpointDir = FLAGS.checkpointDir
        self.model_out_path = FLAGS.model_out_path
        self.total_num = FLAGS.total_num 
        self.max_num = FLAGS.max_num
        self.loss_min = FLAGS.loss_min
        # 学习率我们用此方法设置为动态
        self.learning_rate = FLAGS.learning_rate
        self.buckets = FLAGS.buckets 
        self.checkpointDir = FLAGS.checkpointDir
        self.thread_num = FLAGS.thread_num
        self.min_after_dequeue = FLAGS.min_after_dequeue
        self.train_feature_start = FLAGS.train_feature_start
        self.feature_col_label = FLAGS.feature_col_label
        self.time_label_step = FLAGS.time_label_step
        self.train_path = FLAGS.train_path
        self.is_training = FLAGS.is_training
        
        
        print('分布式LSTM模型初始化结束...')
            
    
    # 正则化
#     def weight_variable(self, shape, l2):
#             if l2 is not None or l2 != '':
#                 with tf.variable_scope(tf.get_variable_scope(), reuse= tf.get_variable_scope().reuse) :   
#                     regularizer = tf.contrib.layers.l2_regularizer(l2)
#                     weight_decay = tf.get_variable('weight_loss',shape,dtype = tf.float32,initializer = tf.contrib.layers.xavier_initializer(),trainable=True)
#                     tf.add_to_collection('losses', regularizer(weight_decay))
#                     return weight_decay
#             else:
#                 return
            
    # 梯度 
    def average_gradients(self,tower_grads):  
        average_grads = []
        for grad_and_vars in zip(*tower_grads):
            grads = [g for g, _ in grad_and_vars]
            grad = tf.stack(grads, 0)
            grad = tf.reduce_mean(grad, 0)
            grad_and_var = (grad, grad_and_vars[0][1])
            average_grads.append(grad_and_var)
        return average_grads
#         average_grads = []
#         for grad_and_vars in zip(*tower_grads):
#             grads = [tf.expand_dims(g, 0) for g, _ in grad_and_vars]
#             grads = tf.concat(grads, 0)
#             grad = tf.reduce_mean(grads, 0)
#             grad_and_var = (grad, grad_and_vars[0][1])
#             average_grads.append(grad_and_var)
#         return average_grads

    
    
    
    ## 加载数据
    def load_data(self):
        # 读取OSS数
        train_file_path = tf.gfile.Glob(os.path.join(self.buckets,self.train_path))
    
        # 创建tf的reader对象
        reader = tf.TextLineReader()
        # 将OSS数据转成序列格式
        file_name_queue_train = tf.train.string_input_producer(train_file_path)
        # 懒加载序列里的value值。
        key_train,value_train = reader.read(file_name_queue_train)
    
         # 初始化特征列,这行是double类型
        record_defaults_train = [["1.0"],["1.0"],["1.0"],["1.0"],["1.0"],["1.0"],["1.0"]] 
    
        col1, col2, col3, col4, col5, col6, col7 = tf.decode_csv(value_train, record_defaults=record_defaults_train)
    
        # 一次读取大量数据,毕竟是测试集，我们不需要batch读取
        # 注意，该方法返回的是个list，后续如果用矩阵计算，需要转成numpy np.array(list)
        # 我们如果想确定随机打乱数据，可以直接用: 
        feature_train = tf.train.shuffle_batch([col5, col6, col7],batch_size=self.total_num, num_threads=self.thread_num, \
                                               capacity=self.total_num, min_after_dequeue = self.min_after_dequeue)  
        
        init = tf.global_variables_initializer()
        with tf.Session() as sess:  
            sess.run(init)
            
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess = sess,coord = coord)   
            
            data = sess.run([feature_train])
            data = np.array(data)
            # 生成的是三维度，需要转成二维,注意这个二维是跟原维度相同即可。
            data = data.reshape(self.train_feature_start,self.total_num).T     
                        
            # 结束读取数据进程
            coord.request_stop()
            coord.join(threads)
            
        return data


    ## 处理训练集数据
    
    def get_train_data(self,data_train,batch_size,batch_size_first,batch_size_end,train_path,time_train_step,feature_col, \
                       time_label_step,feature_col_label,is_training = True):
        data_temp = data_train
               
        data_temp = data_train[batch_size_first:batch_size_end,:]
        X_train = np.zeros(shape = (1))
        y_train = np.zeros(shape = (1))
    
        X_train = np.delete(X_train,0,axis = 0)
        y_train = np.delete(y_train,0,axis = 0)
        
        # 训练集
        for i in data_temp:
            
            list1 = list(i[0].replace('[','').replace(']','').replace('"','').split(','))
            aa_num = len(list1)
            aa = [ float(list1[t1]) for t1 in range(aa_num) if t1 % (feature_col + 1) != 1 ]
            
            list1 = list(i[1].replace('[','').replace(']','').replace('"','').split(','))
            aa_num = len(list1)
            bb = [ float(list1[t2]) for t2 in range(aa_num) if t2 % (feature_col + 1) != 1 ]
          
            aa = aa + bb
            cc = [float(i) for i in i[2].split(',')]
                 
            X_train = np.append(X_train,aa).reshape(-1,time_train_step * feature_col)
            y_train = np.append(y_train,cc).reshape(-1,time_label_step * feature_col_label)
        
        return X_train,y_train

            
            
    # 创建网络对象 
    def build_model(self,batch_size,keep_prob,x,y,scope,num_classes,layer_num,time_train_step,feature_col,cell_num,l2_normal,normal_epsilon):
        # tf.reset_default_graph()   
        with tf.variable_scope(tf.get_variable_scope(), reuse= tf.AUTO_REUSE) :   
            input_x = [x[i] for i in range(batch_size)]
            input_y = [tf.one_hot(y[j],depth = num_classes) for j in range(batch_size)] 
        
            W = {
                 'in' : tf.get_variable('w_in',shape = [feature_col,cell_num],
                                         dtype = tf.float32,
                                         initializer = tf.contrib.layers.xavier_initializer(),trainable=True),
                 'out' : tf.get_variable('w_out',shape = [cell_num,num_classes],
                                         dtype = tf.float32,
                                         initializer = tf.contrib.layers.xavier_initializer(),trainable=True)
                }
            bias = {
                      'in' : tf.get_variable('b_in',shape = [cell_num], initializer=init_ops.constant_initializer(0.1) ,trainable=True),
                      'out' :tf.get_variable('b_out',shape = [num_classes], initializer=init_ops.constant_initializer(0.1) ,trainable=True)
                    }
            
            gamma = tf.get_variable('gamma_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(1),trainable=True)
            beta = tf.get_variable('beta_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(0),trainable=True)
            lstm_mean = tf.get_variable('lstm_mean_in',shape = [time_train_step * feature_col], initializer=init_ops.constant_initializer(0),trainable=True)
            lstm_variance = tf.get_variable('lstm_variance_in',shape = [time_train_step * feature_col],initializer=init_ops.constant_initializer(1),trainable=True)
            
            input_x_normal = tf.nn.batch_normalization(input_x, lstm_mean, lstm_variance, beta, gamma, normal_epsilon)
            
            # input_x_normal = input_x
            # 通过reshape将输入的input_x转化成2维，-1表示函数自己判断该是多少行，列必须是feature_col
            input_x_r = tf.reshape(input_x_normal,[-1,feature_col])                
            
            # relu和dropout操作
            input_x_in_r = tf.nn.relu(tf.matmul(input_x_r,W['in']) + bias['in'])
            input_relu = tf.nn.dropout(input_x_in_r, keep_prob)
            
            # 即LSTM接受：batch_size个，time_train_step行cell_num(神经元个数)列的矩阵
            input_rnn = tf.reshape(input_relu, [-1, time_train_step, cell_num])
            
            # 定义一个带着“开关”的LSTM单层
            def lstm_cell(cell_num,keep_prob):
                cell = rnn.LSTMCell(cell_num, activation = tf.nn.softsign, reuse = tf.get_variable_scope().reuse)
                return rnn.DropoutWrapper(cell, output_keep_prob = keep_prob)
            
            # 拼接网络层 
            lstm_layers = tf.contrib.rnn.MultiRNNCell([lstm_cell(cell_num,keep_prob) for _ in range(layer_num)], state_is_tuple = True)
            # 初始化LSTM网络,以下是固定格式
            init_state = lstm_layers.zero_state(batch_size, dtype = tf.float32)
            # 动态组合
            outputs, state = tf.nn.dynamic_rnn(lstm_layers, inputs = input_rnn, initial_state = init_state, time_major = False)
            h_state = state[-1][1]
            # 我们预测的结果的概率
            logits = tf.matmul(h_state,W['out']) + bias['out']
            # 我们预测的结果
            pre_d = tf.argmax(logits,1)
            # 我们的input_y 是 list类型,与 pre_d 必须要转成tensor才可以。 
            target = tf.argmax(tf.reshape(input_y,[-1,num_classes]),1)
            corr = tf.cast(tf.equal(pre_d,target),tf.float32)
             # 统计正确总数
            correct_num = tf.reduce_sum(corr)
            # 统计acuuary值
            accuracy = tf.reduce_mean(corr)
            
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = input_y,logits = logits)) # 原始LOSS
            regularization_loss = l2_normal * tf.reduce_sum([tf.nn.l2_loss(W['in'])])  # 正则LOSS
            loss = cross_entropy + regularization_loss 
            
            return loss,logits,pre_d,target,correct_num,accuracy
        
    def feed_all_gpu(self,inp_dict, tower_data):
        for i in range(len(self.models)):
            x,y,loss,correct_num,accuracy,grads = self.models[i]
            train_x, train_y = tower_data[i]
            inp_dict[x] = train_x
            inp_dict[y] = train_y
        return inp_dict
    
    # 训练模型
    def train_lstm(self):
        
        
        # 我们要先构建图，再 session,下面就是图的操作,后续所有操作都用session.
        
        
        # with self._graph.as_default():
            
        if self.job_name == "ps":         
            self.server.join()
            print('进入到PS...')
        elif self.job_name == "worker":
            print('进入到WORKER...')
            print('分布式LSTM模型开始构建...')
            self._graph = tf.Graph()  # 构建在一个图中
        
            config = tf.ConfigProto()
            config.gpu_options.allow_growth = True 
            self.session_tf = tf.Session(graph = self._graph,config = config)
            with self._graph.as_default(), tf.device(tf.train.replica_device_setter(worker_device="/job:worker/task:%d" % self.task_index,cluster=self.cluster)):
                global_step = tf.get_variable('global_step', [],initializer=tf.constant_initializer(0), trainable=False)
                self.learning_rate = tf.train.exponential_decay(self.learning_rate,global_step,self.decay_num, self.learning_rate_dec,staircase=True) 
                self.models = []   
                optimizer = tf.contrib.opt.LazyAdamOptimizer(self.learning_rate)
                
                with tf.variable_scope(tf.get_variable_scope(), reuse= tf.AUTO_REUSE):
                    for gpu_id in self.gpu_list:
                         with tf.device('/gpu:%d' % gpu_id):        # 初始化第一个设备
                            print ('gpu:%d...'% gpu_id)
                            with tf.name_scope('tower_%d' % gpu_id) as scope:  # 初始化命名空间
                            #with tf.variable_scope('gpu_v', reuse=gpu_id > self.gpu_list[0]):
                                # 我们的x,y是在循环里,所以放到元组中再取出来。
                                x = tf.placeholder(tf.float32,[self.batch_size,self.time_train_step * self.feature_col])
                                y = tf.placeholder(tf.int32,[self.batch_size,self.output_num])
                                loss,logits,pre_d,target,correct_num,accuracy = \
                                self.build_model(self.batch_size,self.keep_prob,x,y,\
                                scope,self.num_classes,self.layer_num,self.time_train_step,self.feature_col,self.cell_num,self.l2_normal,self.normal_epsilon)
                                # 开启共享
                                tf.get_variable_scope().reuse_variables()
                                # 开始计算梯度
                                grads = optimizer.compute_gradients(loss)
                                # self.models.append((loss,correct_num,accuracy,grads))
                                self.models.append((x,y,loss,correct_num,accuracy,grads))
                # 取出我们的x,y,梯度grads,方便后续run.
                x,y,loss,correct_num,accuracy,grads = zip(*(self.models))
                
                self.loss = tf.reduce_mean(loss)
                self.correct_num = tf.reduce_mean(correct_num)
                self.accuracy = tf.reduce_mean(accuracy)
                # self.train_op = optimizer.apply_gradients(self.average_gradients(grads),global_step = global_step)   
                if self.issync == 1:
                #同步模式计算更新梯度
                    print('进入到同步')
                    self.rep_op = tf.train.SyncReplicasOptimizer(optimizer,replicas_to_aggregate=len(self.worker_hosts),
                                              total_num_replicas=len(self.worker_hosts),use_locking=True)
                    self.train_op = rep_op.apply_gradients(self.average_gradients(grads),global_step = global_step)
                    self.init_token_op = rep_op.get_init_tokens_op()
                    self.chief_queue_runner = rep_op.get_chief_queue_runner()
                else:
                      #异步模式计算更新梯度
                    print('进入到异步')
                    self.train_op = optimizer.apply_gradients(self.average_gradients(grads),global_step = global_step)   
                                                   
                self.init_op = tf.initialize_all_variables()
                self.ckpt_path = os.path.join(self.checkpointDir, self.model_out_path)
                self.saver = tf.train.Saver()
            '''
             含义类似一个监督者， 就是因为分布式了， 很多机器都在运行， 像什么参数初始化，
             保存模型， 写summary什么的，这个supervisoer帮你一起弄起来了， 就不用自己去手工去做这些事情了，
             而且在分布式的环境下设计到各种参数的共享， 其中的过程自己手工写也不好写，
             于是tensorflow就给大家包装好这么一个东西了。 这里的参数is_chief比较重要，
             在所有的计算节点里还是有一个主节点的， 这个主节点来负责初始化参数， 模型的保存，
             summary的保存。 logdir就是保存和装载模型的路径。 不过这个似乎的启动就会去这个logdir的
             目录去看有没有checkpoint的文件，有的话就自动装载了，没有就用init_op指定的初始化参数， 
             好像没有参数指定不让它自动load的；

            '''
            sv = tf.train.Supervisor(graph = self._graph ,is_chief=(self.task_index == 0),init_op=init_op,saver=saver,global_step=global_step,save_model_secs=60)
            with sv.prepare_or_wait_for_session(server.target) as sess:
                # 如果是同步模式
                if FLAGS.task_index == 0 and issync == 1:
                    try:
                        module_file = os.path.join(self.checkpointDir, self.model_out_path)
                        print('模型参数路径: ',module_file)
                        self.saver.restore(sess, module_file)
                        print ("成功加载模型参数")        
                    except:
                        #如果是第一次运行，通过init告知tf加载并初始化变量
                        print ("没有加载成功，进行初始化操作,开始训练模型...")
                        sv.start_queue_runners(sess, [chief_queue_runner])
                        sess.run(init_token_op)
            
                    # 训练集读取
                    NUM = self.total_num // self.batch_size
                    for z in range(self.max_num):
                        # 加载数据
                        data = self.load_data()
                        tower_data = []
                        try:
                            for i in range(NUM):              
                                # 读取训练数据集
                                # 有多少个GPU,就读取多少次。
                                # tower_data = [] 
                                train_x, train_y = self.get_train_data(data_train = data,batch_size = self.batch_size,batch_size_first = 0 + i * self.batch_size , batch_size_end = self.batch_size + i * self.batch_size,train_path = self.train_path,time_train_step = self.time_train_step,feature_col = self.feature_col, time_label_step = self.time_label_step,feature_col_label = self.feature_col_label, is_training = self.is_training)                       
                                
                                tower_data.append((train_x, train_y))
                                
                                if i % self.gpu_num  == 1:
                                    feed_dict = {}
          
                                    feed_dict = self.feed_all_gpu(feed_dict,tower_data)
                                    _, train_loss, correct_num_d,accuracy_d = self.session_tf.run([self.train_op,self.loss,self.correct_num,self.accuracy], feed_dict = feed_dict)
                                    tower_data = []  
        
                                    print("epoch: {0}, step: {1},train_loss: {2},correct_num: {3},accuracy: {4}".format(z + 1,i+1,train_loss,correct_num_d,accuracy_d))
                                    # saver.save(self.session_tf,ckpt_path)
                                    if train_loss < self.loss_min:
                                        print ("训练集均已训练完毕,开始保存模型...")
                                        save_path = saver.save(sess,ckpt_path)
                                        print('模型路径为: ',save_path)
                                        return 
        
                            saver.save(sess,ckpt_path)
            
                        # 防止迭代超出范围,我们设定StopIteration异常,如果执行下面步骤说明迭代已经到了上限,此时我们执行最后一次，然后开始保存模型。
                        except StopIteration:
                            print ("训练集均已训练完毕,开始保存模型...")
                            save_path = saver.save(sess,ckpt_path)
                            print('模型路径为: ',save_path)
                            break  
        
        print('模型训练结束...')
        
        return self
        

# 主函数编写,因为pai里目前不支持调用python主参数,在这里我用FLAGS取代写成定式,后续到其他平台可以修改回来。
def main(is_single,is_distribute):
    FLAGS = Config()

#     if is_distribute == FLAGS.is_distribute and is_single == FLAGS.is_single:
#         lstm_classfi_model = LstmModelMultiClassfi(FLAGS)
#         lstm_classfi_model.train_lstm()
#         return
    if is_distribute != FLAGS.is_distribute and is_single == FLAGS.is_single:
        lstm_classfi_model_distribute = LstmModelMultiClassfiDis(FLAGS)
        lstm_classfi_model_distribute.train_lstm()
        return 
#     if is_distribute != FLAGS.is_distribute and is_single != FLAGS.is_single:
#         return 


# 开启程序
    
if __name__ == '__main__':  
    # tf.app.run(main = main(True,True))
    # tf.app.run()
    main(True,False)


 
 
 
 
 
 
 
 
 
 
 
 
 
   
    
    




  
  
  
