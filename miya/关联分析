一.模型作用
模型本质是通过历史交易次数,来找出物品与物品之间的关联性。
1.通过得到的强关联性进行物品之间的打包销售，提高商家利润。
2.通过物品之间的强关联性可以将物品合理摆放以便客户更快的购买自己的需求，
3.对后续的推荐系统可以提供物品与物品的强关联性，方便后续的权重划分，从而可以进行更精准的排序算法。

二.模型在数丫的使用场景
这次主要是用于物品与物品的强关联进行打包销售，提供利润。
评估指标公式：new_confidence = P(A) ∩ P(B)/P(A)∪P(B)

三.建模过程
1.表名信息：
模型输入表：miya_data_analysis.rpt_xy_comm_all_trade_brand_input   
品牌商集合表：miya_data_analysis.rpt_xy_comm_all_brand  
模型支持度结果表：miya_data_analysis.tmp_allfpmodel_freq 
模型置信度结果表：miya_data_analysis.tmp_allfpmodel_rules
模型全部指标结果表：miya_data_analysis.allfpmodel_freq_support_03
模型应用层结果表(供给数丫产品使用)：miya_data_analysis.allfpmodel_freq_support_result

2.数据提取：抽取所有打上品牌标签的购物篮信息，因为时效性原因,
我们获取2018年以后的数据。

3.特征工程:
(1)构建商品+商品ID的索引表,过滤掉塑料袋+香烟+部分价格不合理的商品脏数据。
(2)计算购物篮的交易频次，最后得到brand+索引组合的数据作为模型的输入数据，另外因为每个品牌品牌商的购物篮数量，种类不同，我们在不同层级品牌设置不同的支持度，目前是根据购物篮数量对支持度进行反比设定，后续会优化该参数

4.模型构建:
将模型输入表与品牌表关联，获取该品牌的购物篮信息和最小支持度，再用FPGROWTH算法进行建模，结果返回到ODPS中。


四.模型环境
ODPS+SPARK.
SPARK配置： 4节点(3worker,1master,运行时只有3worker计算。)
16G内存，8核。目前是阿里云的预付费环境。


五.模型结果与指标解释
模型最终通过支持度和置信度构建出7个指标，其中这次数丫产品按照新置信度来进行排名，其他指标也分别代表了不同的业务场景。

1.支持度(support):
(1)公式: surport(A) = P(A) = ITEM(A) / N 。

(2)数学解释: ITEM是A的出现个数，N是总商品出现次数。

(3)业务解释: 它表示某个商品，或者某个组合商品在一起的次数，比上总商品次数的比值。越高说明这个商品，或者这个组合商品越重要。

2.置信度(confidence):
(1)公式:confidence(A,B) = P(A U B) / P(A) = P(A|B)

(2)数学解释: AUB 表示并集, 也就是A与B同时出现的概率。A是A单独出现的概率。

(3) 业务解释: 商品A出现的概率，与商品A,B同时出现的概率的比值。
这里的A不一定是一个商品，也可能是多个商品。
记住，它仅仅表示先买A，再买B的概率。

3.新置信度(new_confidnece):
p(A∩B)/P(AUB): 这里的新置信度是为了满足A->B和B->A都高，也就是俩者之间的强关联。

4.提升度(grandient):
(1)公式:lift(A,B) = P(A U B) / (P(A) * P(B)) = confidence(A,B) / P(B)

(2)数学解释: A和B的提升度本质就是A和B的置信度/B的出现概率。

(3)业务解释: 提升度出现的原因是因为置信度公式中有不足的地方。假如B出现的概率很高。A的概率不高，那么会导致买了B大部分都会买A。所以导致A,B同时购买的概率很高，但这不能说明A和B的关联性很强。因为这个关联性强的前提是B出现的概率太高了。所以提升度中为了避免这种问题，对B出现的概率进行了相除。
这样假设confidence(A,B)很高是因为B的概率大，那么B越大，被除后结果越小，结果小说明A，B的相关性是因为B自身高而高，而实际相关性并不高。

(4)举例说明: 某超市的某种品牌的水卖的很火，某人买了薯片再买这个水。因为这个薯片自身的销量并不太高，但因为水的销量很高。通过公式得到它俩同时出现的概率很大，所以置信度高，但再除以水的出现概率，这个结果值会降低，说明他俩同时出现概率大，是因为这种水出现的概率太大。


5.CONSINE:
(1)公式: CONSINE(A,B) =  P(AUB)/math.sqrt(P(A) * P(B)) = |P(A|B) * P(B|A)| = math.sqrt(置信度(A->B) * 置信度(B->A)) 

(2)数学解释: 由于加平方根，使其不受到商品总数影响，也是反映相关性，推到公式最后本质是置信度来回的乘积。缺点是只是衡量相关性强弱，无法比较负相关和不想关。

(3)业务解释: 这个公式稍微复杂, 它业务上主要体现 购买商品的前后关系。

(4)举例说明：某超市发现顾客先买牙刷再买牙膏的概率很大，这种就是牙刷和牙膏的置信度大。但发现先买牙膏，再买牙刷的概率不大，这种就可以用CONSINE表示，它的大小是衡量物品之间先后关系的置信度，也就是先买A,再买B的概率大同时满足先买B再买A的概率也大，这个值才大。


6.KUL:
KUL(A,B) = (confidence(A->B) + confidence(B->A))/2
跟上面CONSINE意思一样，只是数学公式有区别，用的是加法。加法与乘法的区别在于，如果先买A，再买B的概率很大，先买B再买A的概率不太大，这个结果也大，但如果是乘法，就会比较小。准确说，这个指标对A和B的先后购买关系不是太看重，更看重的是单纯的置信度。

7.IR(不平衡比)
(1)公式: IR(A,B) = |SUP(A) - SUP(B)| / SUP(A) + SUP(B) - SUP(A∩B)
(2)数学解释: A与B的支持度绝对值差与他俩之和和并集的差值的比值。
(3)业务解释: 这个简单说就是A和B的购买概率相似，这个结果值就比较小，说明越平衡。
(4)实际意义: 商家要找到相似支持度的商品关系时，就用这个指标很好。比如想找俩种牛奶销量相似的商品，比较他们的置信度，提升度，KUL等。那么先用这个指标来筛选即可。





模型处理后的结果表如下：

我们可以根据上面各个指标与产品运营进行商讨，进行更合理的场景分析。

数丫产品结果表如下：




六.模型后续优化目标
考虑到随着时间变化趋势，商品之间的组合会逐渐弱化，新商品组合会逐渐取代老商品，可以在交易次数进行时间分区，然后乘以时间衰减因子，
时间衰减因子公式可以利用牛顿冷却定律：当前权重 = -exp(过去权重*时间间隔)，但因为目前数据中无法精准计算新旧商品，所以此方法待定，后续数据拥有可识别新旧商品时，可以用此方法优化算法。
