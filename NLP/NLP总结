一. NLP工作原理简要



二. NLP十二大算法讲解
1.贝叶斯算法 (生成模型)
(1) 算法背景：目前该算法已经慢慢淡出人们的视野中,一般都是前期数据量小或者进行一些测试使用的算法，但其原理却对NLP领域有着很深的影响,
    也是面试NLP岗位基本必考的算法，面算法工程师/机器学习/数据挖掘中也可能考的算法。

(2) 贝叶斯定理:
    公式: P(A|B) = P(A).P(B|A)/P(B)
    背景: 贝叶斯定理也是贝叶斯学派的思想,通过对已有事情的认知判断,去预测另一个事情的概率。然而这个理论却被频率学派排斥,因为该算法的前提是
          要对事情的主管判断从而初始化一个概率，对这个初始概率进行修正，随着信息增多，逐渐逼近真实的概率，而这个前提在频率派中也认为是不合理。
    公式解读：
          A为目标事件，P(A)是这个目标事件的先验概率。B是新事件， P(A|B)是B出现时A的概率即后验概率。P(B|A)是A出现时B的概率。
          所以：A出现时B的概率+A不出现时B的概率 = P(B|A)*P(A) * P(A_)*P(B|A_) ,P(B|A)/P(B)当作一个修正因子。
          所以：后验概率 = 先验概率 * 修正因子
    
    个人认为的贝叶斯定理的一些应用(个人猜测,只限制于单特征的贝叶斯定理)： 
          用标签去对特征进行一定的筛选(但只限制于我们的已有数据集，可信度并不高，然而筛出来的特征我们可以进行降权或者考虑删除) 
          假设P(A)是目标标签，P(B)是特征。
          比如我们摇色子时每个点的出现概率是 1/6。我们就把P(A)初始化为1/6。同时我们又对摇到1时，自己
          赢的概率设置为1/2。 而喊大赢,喊小赢，喊大输，喊小输。四种情况中赢概率也是 1/2 。这样我们的结论就是:
          在赢的前提下摇中1的概率 = (1/6*1/2)/(1/2）= 1/6。  而事实上，在赢的前提下摇中1的概率就是1/6。因为俩者无关联,这样也推理出摇中1的概率
          这个特征对赢这个结果概率没任何关联，也就是完全独立。
          
     案例理解该定理：
     所谓的概率就是把人们的常识用数学表达出来。也有人说，人脑就是采用贝叶斯方法来工作的。
     但是这里还是不同的。我们人类的大脑虽然也会根据新的证据调整我们的判断，但是我们天生有一种“证实倾向”，我们往往会高估证据的作用，
     但是贝叶斯定理不会，它强迫我们把假设不成立的概率也考虑在内，P(B|A_)和P(A_)，从而纠正了我们的认知偏差。
     让我们再来看一个复杂一点的例子，这是一个经典的案例 ，网上随处都可以找到。
     艾滋病毒(HIV)检测技术的准确度相当惊人。如果一个人真是HIV阳性，血液检测的手段有99.9%的把握把他这个阳性给检查出来而不漏网。
     如果一个人不携带HIV，那么检测手段的精度更高，达到99.99%——也就是说只有0.01%的可能性会冤枉他。已知一般人群中HIV携带者的比例是0.01%。
     现在假设我们随便在街头找一个人给他做检查，发现检测结果是HIV阳性，那么请问，这个人真的携带HIV的可能性是多大呢？
     我们使用贝叶斯定理。A表示“这个人真的携带HIV”，B表示“检测出HIV”，那么根据现有条件，P(A) = 0.01%，P(B|A) = 99.9%，P(B|A-) = 0.01%，
     带入公式，计算得到P(A|B) = 0.01% * 99.9% * (99.9%*0.01% + 0.01%*99.99%) = 50%！
     答案或许和你的直觉不一致，即使在这么惊人的检测准确度之下，哪怕这个人真的被检测到HIV阳性，他真有HIV的可能性也只有50%。
          
     具体高级认知: https://www.jianshu.com/p/7e8504e9b929
 (3) 基本方法
     a. 假设输入数据为 : T = {(x1,y1),(x2,y2),...,(xn,yn)}. x为特征向量,y为标签。 => P(X,Y)是独立同分布产生。
     朴素贝叶斯通过先验概率分布(P(Y=ck)) 和 条件概率分布 P(X1=x1,X1=x2...|Y=ck) 。去学习联合概率P(X,Y)。条件概率是假设概率，先验概率是已知
     的事务的推断的概率。
     b. 这里解析是我们知道标签发生的概率和该标签下各个特征的概率,然后去学习该特征下发生该类别的概率，也就是P(X∩Y)交集，也就是联合概率。
     c. 该算法的参数总数估计：
        条件概率分布P(X=x|Y=ck)有指数级数量的参数,其估计实际是不可行的。假设特征x有Sj个取值，Y有K个。那么参数为K∏(连乘)Sj(j=1...n)
        也就是类别数*特征数。
        
        
      
     
 
     
     
     
     
  
